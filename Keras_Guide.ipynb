{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Guide.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yskim0/study/blob/master/Keras_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj8E6M3X7cVL",
        "colab_type": "text"
      },
      "source": [
        "#Keras Guide\n",
        "\n",
        "\n",
        "* Sequential 모델\n",
        "\n",
        "케라스에서는 층(layer)을 조합하여 모델을 만듦.\n",
        "\n",
        "`모델은 층의 그래프`임\n",
        "\n",
        "`tf.keras.Sequenetial`\n",
        "\n",
        "& Sequential보다 더 고수준의 모델을 구성하는 방법을 배우려면 다음을 참고하세요:\n",
        "\n",
        "[케라스 함수형 API 가이드 ](https://www.tensorflow.org/guide/keras/functional)\n",
        "\n",
        "[클래스 상속을 통하여 층과 모델을 밑바닥부터 만드는 방법](https://www.tensorflow.org/guide/keras/custom_layers_and_models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZnwvl3-7USI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "bbb2449a-d2df-4f47-839d-c8180ec11d34"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "# 64개의 유닛을 가진 완전 연결 층을 모델에 추가합니다:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# 또 하나를 추가합니다:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# 10개의 출력 유닛을 가진 소프트맥스 층을 추가합니다:\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyBDqIpc8EBF",
        "colab_type": "text"
      },
      "source": [
        "* 층 설정\n",
        "\n",
        "\n",
        "`activation` \n",
        "\n",
        "층의 활성화 함수를 설정합니다.\n",
        "\n",
        "이 매개변수에는 기본으로 제공되는 함수의 이름을 쓰거나 호출 가능한 객체를 지정할 수 있습니다.\n",
        "\n",
        "기본값은 활성화 함수를 적용하지 않는 것입니다.\n",
        "\n",
        "`kernel_initializer와 bias_initializer`\n",
        "\n",
        "층의 가중치(weight)(커널(kernel)과 절편(bias))를 초기화하는 방법입니다. \n",
        "\n",
        "내장 함수나 호출 가능한 객체를 지정합니다. \n",
        "\n",
        "기본값은 \"glorot_uniform\" 초기화입니다.\n",
        "\n",
        "\n",
        "`kernel_regularizer와 bias_regularizer`\n",
        "\n",
        "L1 또는 L2 규제(regularization)와 같이 층의 가중치(커널과 절편)에 적용할 규제 방법을 지정합니다. 기본값은 규제를 적용하지 않는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tD-HNdt77nK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "843a5ffe-3ac9-402e-fbaa-3af7c6c311a1"
      },
      "source": [
        "# 시그모이드 활성화 층을 만듭니다:\n",
        "layers.Dense(64, activation='sigmoid')\n",
        "# 또는 다음도 가능합니다:\n",
        "layers.Dense(64, activation=tf.keras.activations.sigmoid)\n",
        "\n",
        "# 커널 행렬에 L1 규제가 적용된 선형 활성화 층. 하이퍼파라미터 0.01은 규제의 양을 조절합니다:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "\n",
        "# 절편 벡터에 L2 규제가 적용된 선형 활성화 층. 하이퍼파라미터 0.01은 규제의 양을 조절합니다:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# 커널을 랜덤한 직교 행렬로 초기화한 선형 활성화 층:\n",
        "layers.Dense(64, kernel_initializer='orthogonal')\n",
        "\n",
        "# 절편 벡터를 상수 2.0으로 설정한 선형 활성화 층:\n",
        "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7f859d537668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDC9Riws8jQA",
        "colab_type": "text"
      },
      "source": [
        "## 훈련과 평가\n",
        "\n",
        "* `tf.keras.Model.compile` (3가지 매개 변수)\n",
        "\n",
        "\n",
        "\n",
        "1.   `optimizer`\n",
        "  훈련 과정을 설정함. \n",
        "  \n",
        "  기본 매개변수를 사용할 경우 'adam'이나 'sgd'와 같이 문자열로 지정할 수도 있습니다.\n",
        "\n",
        "2.   `loss`\n",
        "  최적화 과정에서 최소화될 손실 함수(loss function)를 설정\n",
        "\n",
        "  평균 제곱 오차(mse)와 categorical_crossentropy, binary_crossentropy 등이 자주 사용\n",
        "\n",
        "  손실 함수의 이름을 지정하거나 tf.keras.losses 모듈 아래의 호출 가능한 객체를 전달 가능\n",
        "\n",
        "3.    `metrics`\n",
        "  훈련을 모니터링하기 위해 사용됨.\n",
        "\n",
        "4.    추가적으로 모델의 훈련과 평가를 즉시 실행하려면 run_eagerly=True 매개변수를 전달하면 됨.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# 평균 제곱 오차로 회귀 모델을 설정합니다.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss='mse',       # 평균 제곱 오차\n",
        "              metrics=['mae'])  # 평균 절댓값 오차\n",
        "\n",
        "# 크로스엔트로피 손실 함수로 분류 모델을 설정합니다.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZoEsWbr8fes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "08048dbc-1d5c-4e69-8b3d-1c68e3f54bad"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "# 64개의 유닛을 가진 완전 연결 층을 모델에 추가합니다:\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "# 또 하나를 추가합니다:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# 10개의 출력 유닛을 가진 소프트맥스 층을 추가합니다:\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up1NIbH-9kLp",
        "colab_type": "text"
      },
      "source": [
        "* `tf.keras.Model.fit` (3가지 매개 변수)\n",
        "\n",
        "1.  `epochs`\n",
        "\n",
        "훈련은 에포크로 구성됨.\n",
        " \n",
        "한 에포크는 전체 입력 데이터를 한번 순회하는 것 (작은 배치로 나누어 수행)\n",
        "\n",
        "2.  `batch size`\n",
        "\n",
        "넘파이 데이터를 전달하면 **모델은 데이터를 작은 배치로 나누고 훈련 과정에서 이 배치를 순회**\n",
        "\n",
        "이 정수 값은 배치의 크기를 지정. \n",
        "\n",
        "(전체 샘플 개수가 배치 크기로 나누어 떨어지지 않으면 마지막 배치의 크기는 더 작을 수 있음.)\n",
        "\n",
        "3.  `validation_data`\n",
        "\n",
        "모델의 프로토타입(prototype)을 만들 때는 **검증 데이터(validation data)**에서 간편하게 성능을 모니터링해야 합니다. \n",
        "\n",
        "입력과 레이블(label)의 튜플을 이 매개변수로 전달하면 \n",
        "\n",
        "에포크가 끝날 때마다 추론 모드(inference mode)에서 **전달된 데이터의 손실과 측정 지표를 출력**합니다.\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "> 넘파이 데이터를 사용한 훈련\n",
        "\n",
        "데이터셋이 작은 경우 넘파이(NumPy) 배열을 메모리에 적재하여 모델을 훈련하고 평가합니다. \n",
        "\n",
        "모델은 fit 메서드를 통해서 훈련 데이터를 학습합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rillUuKT8nYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b067a80f-c4ae-4fc1-fe98-2a70d5586853"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 385us/sample - loss: 12.2870 - acc: 0.0960\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 52us/sample - loss: 17.9181 - acc: 0.0980\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 63us/sample - loss: 33.7644 - acc: 0.1000\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 61us/sample - loss: 64.3578 - acc: 0.1060\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 60us/sample - loss: 111.6877 - acc: 0.1040\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 64us/sample - loss: 166.5614 - acc: 0.1040\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 56us/sample - loss: 231.0664 - acc: 0.1070\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 60us/sample - loss: 299.3644 - acc: 0.1110\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 346.8318 - acc: 0.1070\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 63us/sample - loss: 374.8570 - acc: 0.0940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f859d523f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcjg6nRC9q76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ac102b8e-0c9b-40f2-add1-b3b4b823717b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "val_data = np.random.random((100, 32))\n",
        "val_labels = np.random.random((100, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 91us/sample - loss: 389.4693 - acc: 0.1000 - val_loss: 411.2200 - val_acc: 0.1200\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 55us/sample - loss: 367.7762 - acc: 0.1090 - val_loss: 371.8433 - val_acc: 0.1200\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 52us/sample - loss: 327.9860 - acc: 0.0990 - val_loss: 291.8529 - val_acc: 0.1800\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 57us/sample - loss: 239.2887 - acc: 0.0920 - val_loss: 211.6064 - val_acc: 0.1200\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 65us/sample - loss: 146.4238 - acc: 0.0940 - val_loss: 97.5406 - val_acc: 0.1200\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 56us/sample - loss: 77.2906 - acc: 0.1110 - val_loss: 56.6985 - val_acc: 0.1200\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 56us/sample - loss: 85.1002 - acc: 0.1120 - val_loss: 70.3303 - val_acc: 0.0600\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 59us/sample - loss: 92.5609 - acc: 0.1070 - val_loss: 98.6746 - val_acc: 0.1100\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 54us/sample - loss: 104.7921 - acc: 0.1020 - val_loss: 130.6467 - val_acc: 0.1200\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 55us/sample - loss: 133.0025 - acc: 0.1090 - val_loss: 138.2090 - val_acc: 0.0900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f859d396f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAWbwUwW_Bbn",
        "colab_type": "text"
      },
      "source": [
        "*  tf.data 데이터셋을 사용한 훈련\n",
        "\n",
        "데이터셋 API를 사용하여 대규모 데이터셋이나 복수의 장치로 확장시킬 수 있습니다. \n",
        "\n",
        "fit 메서드에 tf.data.Dataset 객체를 전달\n",
        "\n",
        "**여기에서 fit 메서드는 steps_per_epoch 매개변수를 사용합니다. \n",
        "다음 에포크로 넘어가기 전에 모델이 수행할 훈련 단계 횟수입니다. Dataset이 배치 데이터를 생성하기 때문에 batch_size가 필요하지 않습니다.**\n",
        "\n",
        "Dataset은 검증 데이터에도 사용 가능\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af6-QdrD-1jn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "53aa8117-dafd-4316-ab00-94593ce4d848"
      },
      "source": [
        "# 예제 `Dataset` 객체를 만듭니다:\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "# Dataset에서 `fit` 메서드를 호출할 때 `steps_per_epoch` 설정을 잊지 마세요.\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Train on 30 steps\n",
            "Epoch 1/10\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 129.6700 - acc: 0.0990\n",
            "Epoch 2/10\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 202.1968 - acc: 0.0938WARNING:tensorflow:Your dataset ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f859d3eec50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QahasYZd_Umc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "29c1f49b-0d51-4f46-ee99-028204f24f2f"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "\n",
        "model.fit(dataset, epochs=10,\n",
        "          validation_data=val_dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Train on 32 steps, validate on 4 steps\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 179.3362 - acc: 0.0930 - val_loss: 188.4568 - val_acc: 0.0700\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 170.0612 - acc: 0.1100 - val_loss: 160.2992 - val_acc: 0.1200\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 190.4937 - acc: 0.0780 - val_loss: 209.3025 - val_acc: 0.1500\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 284.2324 - acc: 0.1010 - val_loss: 213.4948 - val_acc: 0.1100\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 285.1647 - acc: 0.1240 - val_loss: 272.3232 - val_acc: 0.0900\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 289.6243 - acc: 0.0990 - val_loss: 362.7060 - val_acc: 0.0900\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 327.4941 - acc: 0.1050 - val_loss: 311.5286 - val_acc: 0.0600\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 286.1185 - acc: 0.1040 - val_loss: 338.0639 - val_acc: 0.1200\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 343.6555 - acc: 0.0860 - val_loss: 445.3741 - val_acc: 0.1200\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 452.2570 - acc: 0.1000 - val_loss: 417.5918 - val_acc: 0.1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8596c71cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MizDDeBr_ylx",
        "colab_type": "text"
      },
      "source": [
        "##평가와 예측\n",
        "\n",
        "`tf.keras.Model.evaluate`와 `tf.keras.Model.predict` 메서드에는 \n",
        "\n",
        "넘파이 배열이나 tf.data.Dataset을 사용할 수 있습니다.\n",
        "\n",
        "주어진 데이터로 추론 모드의 손실이나 지표를 평가합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwL5iVuf_rnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "58f20833-1258-4e3c-df7b-38bf95ac9561"
      },
      "source": [
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels, batch_size=32)\n",
        "\n",
        "model.evaluate(dataset, steps=30)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 56us/sample - loss: 434.4147 - acc: 0.1080\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 434.3732 - acc: 0.1083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[434.37316080729164, 0.108333334]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl_RrSM9__gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6e55e6c-68f6-4566-9649-bce7adb280f7"
      },
      "source": [
        "result = model.predict(data, batch_size=32)\n",
        "print(result.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz46-MtzBSAA",
        "colab_type": "text"
      },
      "source": [
        "## 고급 모델 만들기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1XXSgsuDj-p",
        "colab_type": "text"
      },
      "source": [
        "### 함수형 API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp69Sx0eARpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cf89bdb2-93d2-4c77-94bc-18798628fcd1"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(32,))  # 입력 플레이스홀더를 반환합니다.\n",
        "\n",
        "# 층 객체는 텐서를 사용하여 호출되고 텐서를 반환합니다.\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "predictions = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# 컴파일 단계는 훈련 과정을 설정합니다.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5번의 에포크 동안 훈련합니다.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 116us/sample - loss: 12.5132 - acc: 0.1030\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 42us/sample - loss: 18.0297 - acc: 0.0980\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 45us/sample - loss: 29.4902 - acc: 0.1030\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 41us/sample - loss: 45.0870 - acc: 0.1080\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 42us/sample - loss: 63.5550 - acc: 0.1090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f859e0e7b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyttt-4GBwln",
        "colab_type": "text"
      },
      "source": [
        "###모델 클라스 상속\n",
        "\n",
        "tf.keras.Model 클래스를 상속하고 자신만의 정방향 패스(forward pass)을 정의하여 완전히 커스터마이징된 모델을 만들 수 있습니다. \n",
        "\n",
        "__init__ 메서드에서 층을 만들어 클래스 객체의 속성으로 지정합니다. 정방향 패스는 call 메서드에 정의합니다.\n",
        "\n",
        "즉시 실행이 활성화되어 있을 때 정방향 패스를 명령형 프로그래밍 방식으로 작성할 수 있기 때문에 모델 클래스 상속이 매우 유용합니다.\n",
        "\n",
        "*노트*: 정방향 패스를 항상 명령형 프로그래밍 방식으로 실행하려면 super 객체의 생성자를 호출할 때 dynamic=True를 지정하세요.\n",
        "\n",
        "중요 포인트: 작업에 맞는 API를 사용하세요. 모델 클래스 상속은 유연성을 제공하지만 복잡도가 증가하고 사용자 오류가 발생할 가능성이 높아집니다. 가능한한 함수형 API를 사용하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhDpYAfxBokr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(MyModel, self).__init__(name='my_model')\n",
        "    self.num_classes = num_classes\n",
        "    # 층을 정의합니다.\n",
        "    self.dense_1 = layers.Dense(32, activation='relu')\n",
        "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # 정방향 패스를 정의합니다.\n",
        "    # `__init__` 메서드에서 정의한 층을 사용합니다.\n",
        "    x = self.dense_1(inputs)\n",
        "    return self.dense_2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2UknKcZCEsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "3f30cee9-f0b0-4a00-a720-3be71b93f200"
      },
      "source": [
        "model = MyModel(num_classes=10)\n",
        "\n",
        "# 컴파일 단계는 훈련 과정을 설정합니다.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5번의 에포크 동안 훈련합니다.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 212us/sample - loss: 11.4770 - acc: 0.1100\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 45us/sample - loss: 11.4546 - acc: 0.1210\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 41us/sample - loss: 11.4498 - acc: 0.1070\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 50us/sample - loss: 11.4472 - acc: 0.1070\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 43us/sample - loss: 11.4456 - acc: 0.1020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f857f619780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfsJxHL0COeI",
        "colab_type": "text"
      },
      "source": [
        "### 맞춤형 층\n",
        "\n",
        " `tf.keras.layers.Layer` 클래스를 상속하고 다음 메서드를 구현\n",
        "\n",
        "* `__init__`: 이 층에서 사용되는 하위 층을 정의할 수 있습니다.\n",
        "* `build`: 층의 가중치를 만듭니다. add_weight 메서드를 사용해 가중치를 추가합니다.\n",
        "* `call`: 정방향 패스를 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZdSrXEyCLbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLayer(layers.Layer):\n",
        "\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    # 이 층에서 훈련할 가중치 변수를 만듭니다.\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=(input_shape[1], self.output_dim),\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super(MyLayer, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    return base_config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R9Gs7G8CmEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "0e807887-641d-4cf8-f9b9-1761f06a8813"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    MyLayer(10),\n",
        "    layers.Activation('softmax')])\n",
        "\n",
        "# 컴파일 단계는 훈련 과정을 설정합니다.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5번의 에포크 동안 훈련합니다.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Train on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 85us/sample - loss: 11.4647 - acc: 0.0940\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 39us/sample - loss: 11.4645 - acc: 0.0910\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 42us/sample - loss: 11.4649 - acc: 0.0910\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 37us/sample - loss: 11.4644 - acc: 0.0920\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 40us/sample - loss: 11.4646 - acc: 0.0940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f857f6c8208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqOcC0SMCv2k",
        "colab_type": "text"
      },
      "source": [
        "## 콜백\n",
        "\n",
        "콜백(callback)은 훈련하는 동안 모델의 동작을 변경하고 확장하기 위해 전달하는 객체\n",
        "\n",
        "자신만의 콜백을 작성하거나 다음과 같은 내장 `tf.keras.callbacks`을 사용할 수 있음:\n",
        "\n",
        "* `tf.keras.callbacks.ModelCheckpoint`: 일정 간격으로 모델의 체크포인트를 저장합니다.\n",
        "* `tf.keras.callbacks.LearningRateScheduler`: 학습률(learning rate)을 동적으로 변경합니다.\n",
        "* `tf.keras.callbacks.EarlyStopping`: 검증 성능이 향상되지 않으면 훈련을 중지합니다.\n",
        "* `tf.keras.callbacks.TensorBoard`: 텐서보드를 사용하여 모델을 모니터링합니다.\n",
        "\n",
        "\n",
        "tf.keras.callbacks.Callback을 사용하려면 모델의 fit 메서드에 전달"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88WWC5WkCnre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4b4d36cb-7960-4ba6-a457-ac1b6254ddb0"
      },
      "source": [
        "callbacks = [\n",
        "  # `val_loss`가 2번의 에포크에 걸쳐 향상되지 않으면 훈련을 멈춥니다.\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "  # `./logs` 디렉토리에 텐서보드 로그를 기록니다.\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 117us/sample - loss: 11.4642 - acc: 0.0950 - val_loss: 11.6625 - val_acc: 0.0400\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 45us/sample - loss: 11.4643 - acc: 0.0940 - val_loss: 11.6629 - val_acc: 0.0400\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 44us/sample - loss: 11.4649 - acc: 0.0920 - val_loss: 11.6632 - val_acc: 0.0400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f857f6b7240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I40sXXy2DR8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}